{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f8b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem\n",
    "from threading import Thread, Lock\n",
    "import threading\n",
    "import pickle\n",
    "# import undetected_chromedriver.v2 as uc\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0cc210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем всю ленту новостей\n",
    "\n",
    "def get_source_html(url, driver):\n",
    "    counter = 0\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(30)\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    action = ActionChains(driver)\n",
    "    el = driver.find_element(By.CLASS_NAME, 'list-more')\n",
    "    action.move_to_element_with_offset(el, 5, 5)\n",
    "    action.click()\n",
    "    action.perform()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    try:\n",
    "        counter += 2\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if counter >= 300 and counter % 20 == 0:\n",
    "                with  open(f'ria_economy/raw_preview/news_ria{counter}.html', 'w') as file:\n",
    "                    file.write(driver.page_source)\n",
    "\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(0.5)\n",
    "            counter += 1\n",
    "\n",
    "    except Exception as _ex:\n",
    "        print(_ex)\n",
    "\n",
    "    finally:\n",
    "        driver.close()\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1b58a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем ссылки из ленты новостей\n",
    "\n",
    "def get_file_urls(file_path):\n",
    "    import os\n",
    "    files = sorted(os.listdir(file_path))[1:]\n",
    "\n",
    "    urls = []\n",
    "    c = 1\n",
    "    for f in files:\n",
    "\n",
    "        with open(file_path + f'/{f}') as file:\n",
    "            src = file.read()\n",
    "        \n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        items_divs = soup.find_all('div', class_='list-item')\n",
    "\n",
    "        for item in items_divs:\n",
    "            item_url = item.find('div', class_='list-item__content').find('a').get('href')\n",
    "            if item_url not in urls:\n",
    "                urls.append(item_url)\n",
    "\n",
    "        print(f'Ссылки из файлов {c} из {len(files)} получены')\n",
    "        c+=1\n",
    "\n",
    "    with open(f'ria_economy/urls.txt', 'w') as file:\n",
    "        for url in urls:\n",
    "            file.write(f'{url}\\n')\n",
    "\n",
    "        print(f'Ссылки сохранены')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38fc4e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/2n44mlkj7nbdwb651dd78pwc0000gn/T/ipykernel_810/1943467916.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChrome(ChromeDriverManager()\u001b[39m.\u001b[39minstall())\n\u001b[0;32m----> 3\u001b[0m get_source_html(url\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhttps://ria.ru/politics/\u001b[39;49m\u001b[39m'\u001b[39;49m, driver\u001b[39m=\u001b[39;49mdriver)\n",
      "Cell \u001b[0;32mIn [17], line 26\u001b[0m, in \u001b[0;36mget_source_html\u001b[0;34m(url, driver)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m counter \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m \u001b[39mand\u001b[39;00m counter \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mwith\u001b[39;00m  \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mria_economy/raw_preview/news_ria\u001b[39m\u001b[39m{\u001b[39;00mcounter\u001b[39m}\u001b[39;00m\u001b[39m.html\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m---> 26\u001b[0m         file\u001b[39m.\u001b[39mwrite(driver\u001b[39m.\u001b[39;49mpage_source)\n\u001b[1;32m     28\u001b[0m driver\u001b[39m.\u001b[39mexecute_script(\u001b[39m\"\u001b[39m\u001b[39mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:540\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpage_source\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    Gets the source of the current page.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39m            driver.page_source\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET_PAGE_SOURCE)[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:427\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    424\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m    426\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_value(params)\n\u001b[0;32m--> 427\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    429\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py:344\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    343\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 344\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py:366\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    363\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 366\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    367\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/urllib3/request.py:74\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m urlopen_kw[\u001b[39m\"\u001b[39m\u001b[39mrequest_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m url\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_url_methods:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/urllib3/request.py:96\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m fields:\n\u001b[1;32m     94\u001b[0m     url \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m urlencode(fields)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:1347\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1347\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1348\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1349\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:307\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    309\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:268\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 268\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    270\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Запускаем функцию для сбора ссылок, останавливаем вручную, потому что нельзя листать ее до бесконечности.\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "get_source_html(url='https://ria.ru/politics/', driver=driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df517986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ссылки из файлов 1 из 23 получены\n",
      "Ссылки из файлов 2 из 23 получены\n",
      "Ссылки из файлов 3 из 23 получены\n",
      "Ссылки из файлов 4 из 23 получены\n",
      "Ссылки из файлов 5 из 23 получены\n",
      "Ссылки из файлов 6 из 23 получены\n",
      "Ссылки из файлов 7 из 23 получены\n",
      "Ссылки из файлов 8 из 23 получены\n",
      "Ссылки из файлов 9 из 23 получены\n",
      "Ссылки из файлов 10 из 23 получены\n",
      "Ссылки из файлов 11 из 23 получены\n",
      "Ссылки из файлов 12 из 23 получены\n",
      "Ссылки из файлов 13 из 23 получены\n",
      "Ссылки из файлов 14 из 23 получены\n",
      "Ссылки из файлов 15 из 23 получены\n",
      "Ссылки из файлов 16 из 23 получены\n",
      "Ссылки из файлов 17 из 23 получены\n",
      "Ссылки из файлов 18 из 23 получены\n",
      "Ссылки из файлов 19 из 23 получены\n",
      "Ссылки из файлов 20 из 23 получены\n",
      "Ссылки из файлов 21 из 23 получены\n",
      "Ссылки из файлов 22 из 23 получены\n",
      "Ссылки из файлов 23 из 23 получены\n",
      "Ссылки сохранены\n"
     ]
    }
   ],
   "source": [
    "# Вытаскиваем ссылки\n",
    "file_path = '/Users/eugenborisenko/Desktop/Универ мага/Диссертация/Парсеры сайтов/ria_politics/raw_preview'\n",
    "get_file_urls(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14404aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем сохраненные ссылки\n",
    "with open('ria_politics/urls.txt') as file:\n",
    "    urls = file.read()\n",
    "urls = urls.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8497fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем набор user agent, чтобы сайт не так быстро блочил\n",
    "software_names = [SoftwareName.CHROME.value]\n",
    "operating_systems = [OperatingSystem.WINDOWS.value, OperatingSystem.LINUX.value]   \n",
    "\n",
    "user_agent_rotator = UserAgent(software_names=software_names, operating_systems=operating_systems, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052663f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m'\u001b[39m: [], \u001b[39m'\u001b[39m\u001b[39mdata_or_ex\u001b[39m\u001b[39m'\u001b[39m: []}\n\u001b[0;32m----> 2\u001b[0m total_news \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(urls)\n\u001b[1;32m      3\u001b[0m current_value \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urls' is not defined"
     ]
    }
   ],
   "source": [
    "# Создаем массив данных, куда будут все склвдывать потоки\n",
    "data = {'link': [], 'data_or_ex': []}\n",
    "total_news = len(urls)\n",
    "current_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d31fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пишем функцию для парсинга нужных данных с многопоточностью.\n",
    "\n",
    "def parse_from_link(link, user_agent, current_value):\n",
    "    if current_value % 10 == 0:\n",
    "        user_agent = user_agent_rotator.get_random_user_agent()\n",
    "\n",
    "    try:\n",
    "        with requests.session() as s:\n",
    "            txt = s.get(link, headers={'User-Agent':user_agent}).text\n",
    "            soup = BeautifulSoup(txt, 'lxml')\n",
    "            try:\n",
    "                timestamp = soup.find('div', class_='article__info-date').find('a').text\n",
    "            except:\n",
    "                timestamp = 'No time'\n",
    "            \n",
    "            try:\n",
    "                title = soup.find('h1', class_='article__title').text\n",
    "            except:\n",
    "                title = 'No title'\n",
    "            try:\n",
    "                announce = soup.find('div', class_='article__announce-text').text\n",
    "            except:\n",
    "                announce = 'No announce'\n",
    "            try:\n",
    "                text = soup.find('div', class_='article__body js-mediator-article mia-analytics').text\n",
    "            except:\n",
    "                text = 'No text'\n",
    "            return timestamp, title, announce, text\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(link)\n",
    "        print(ex)\n",
    "        return ex\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        return\n",
    "\n",
    "\n",
    "def parse(lock, links, save_evry):\n",
    "\n",
    "    global data, total_news, current_value\n",
    "\n",
    "    user_agent = user_agent_rotator.get_random_user_agent()\n",
    "\n",
    "    while current_value < total_news:\n",
    "        with lock:\n",
    "            thread_value = current_value\n",
    "            link = links[current_value]\n",
    "            current_value += 1\n",
    "        \n",
    "        parsed = parse_from_link(link, user_agent, thread_value)\n",
    "        if parsed == None:\n",
    "            return\n",
    "\n",
    "        with lock:\n",
    "            data['link'].append(link)\n",
    "            data['data_or_ex'].append(parsed)\n",
    "            if thread_value % save_evry == 0:\n",
    "                with open(f'ria_economy/raw_cites/{thread_value}_skipped.pkl', 'wb') as f:\n",
    "                    pickle.dump(data, f)\n",
    "                    print(f'{thread_value} saved')\n",
    "                data.clear()\n",
    "                data['link'] = []\n",
    "                data['data_or_ex'] = []\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    with open(f'ria_economy/raw_cites/{thread_value}_skipped.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    return 'Конец'\n",
    "\n",
    "def start_parsing(links, n_threads=3, save_evry=15000):\n",
    "    \n",
    "    lock = Lock()\n",
    "    threads = []\n",
    "    run_event = threading.Event()\n",
    "    run_event.set()\n",
    "\n",
    "    for i in range(n_threads):\n",
    "        t = Thread(target=parse, args=(lock, links, save_evry))\n",
    "        t.start()\n",
    "        time.sleep(2)\n",
    "        threads.append(t)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запускаем функцию\n",
    "start_parsing(urls, n_threads=2, save_evry=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b3db22d",
   "metadata": {},
   "source": [
    "### Дальше по сути тот же код, что и был выше, но я там докачивал пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3d58c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ria_politics/urls_retry.txt') as file:\n",
    "    urls = file.read()\n",
    "urls = urls.split('\\n')\n",
    "\n",
    "data = {'link': [], 'data_or_ex': []}\n",
    "total_news = len(urls)\n",
    "current_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4dd91fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 saved\n",
      "200 saved\n",
      "400 saved\n",
      "\n",
      "Invalid URL '': No scheme supplied. Perhaps you meant http://?\n"
     ]
    }
   ],
   "source": [
    "start_parsing(urls, n_threads=2, save_evry=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b75015",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ria_economy/urls_retry.txt') as file:\n",
    "    urls = file.read()\n",
    "urls = urls.split('\\n')\n",
    "\n",
    "data = {'link': [], 'data_or_ex': []}\n",
    "total_news = len(urls)\n",
    "current_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43798cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 saved\n",
      "200 saved\n",
      "400 saved\n",
      "600 saved\n",
      "800 saved\n",
      "1000 saved\n",
      "1200 saved\n",
      "1400 saved\n",
      "1600 saved\n",
      "1800 saved\n",
      "2000 saved\n",
      "2200 saved\n",
      "2400 saved\n",
      "2600 saved\n",
      "2800 saved\n",
      "3000 saved\n",
      "\n",
      "Invalid URL '': No scheme supplied. Perhaps you meant http://?\n"
     ]
    }
   ],
   "source": [
    "start_parsing(urls, n_threads=2, save_evry=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e78b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ria_politics/urls_retry.txt') as file:\n",
    "    urls = file.read()\n",
    "urls = urls.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "205c08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_left(file_path):\n",
    "    urls = []\n",
    "    files = sorted(os.listdir(f'{file_path}'))\n",
    "    \n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.DataFrame(pd.read_pickle(f'{file_path}/{file}'))\n",
    "            df['tp'] = df['data_or_ex'].map(lambda x: isinstance(x, tuple))\n",
    "            df.drop(df[df.tp == True].index, inplace=True)\n",
    "            df = df[df['link'].str.contains('https://ria.ru/')==True]\n",
    "            url = df['link'].astype(str).to_list()\n",
    "            urls.extend(url)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3731b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_path = '/Users/eugenborisenko/Desktop/Универ мага/Диссертация/Парсеры сайтов/ria_politics/raw_cites'\n",
    "economics_path = '/Users/eugenborisenko/Desktop/Универ мага/Диссертация/Парсеры сайтов/ria_economy/raw_cites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fda35283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays must be of the same length\n",
      "All arrays must be of the same length\n",
      "invalid load key, '\\x00'.\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n"
     ]
    }
   ],
   "source": [
    "urls_politics = urls_left(politics_path)\n",
    "urls_economics = urls_left(economics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dc21b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ria_politics/urls_retry.txt', 'w') as file:\n",
    "    for url in urls_politics:\n",
    "        file.write(f'{url}\\n')\n",
    "\n",
    "with open(f'ria_economy/urls_retry.txt', 'w') as file:\n",
    "    for url in urls_economics:\n",
    "        file.write(f'{url}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984e27bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>announce</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ria.ru/20110211/333378123.html</td>\n",
       "      <td>19:57 11.02.2011</td>\n",
       "      <td>активист хабаровск приносить консульство япони...</td>\n",
       "      <td>активист молодежный движение хабаровск приноси...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ria.ru/20110211/333385555.html</td>\n",
       "      <td>20:13 11.02.2011</td>\n",
       "      <td>токио протестовать против медведев снова поеха...</td>\n",
       "      <td>выражать серьезный протест отношение визит сос...</td>\n",
       "      <td>москва 11 фев риа новость япония категорически...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ria.ru/20110211/333377675.html</td>\n",
       "      <td>19:56 11.02.2011</td>\n",
       "      <td>иран назло весь враг</td>\n",
       "      <td>иран отмечать 32 годовщина исламский революция...</td>\n",
       "      <td>иран отмечать 32 годовщина исламский революция...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ria.ru/20110211/333366199.html</td>\n",
       "      <td>19:26 11.02.2011</td>\n",
       "      <td>российский нация должный состоять самобытный н...</td>\n",
       "      <td>большой задача касаться формирование будущий и...</td>\n",
       "      <td>уфа 11 фев риа новость президент рф дмитрий ме...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ria.ru/20110211/333358165.html</td>\n",
       "      <td>19:05 11.02.2011</td>\n",
       "      <td>медведев называть межнациональный единство пер...</td>\n",
       "      <td>межнациональный единство мочь государство оно ...</td>\n",
       "      <td>уфа 11 фев риа новость руководитель весь регио...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>https://ria.ru/20110203/329935025.html</td>\n",
       "      <td>17:32 03.02.2011</td>\n",
       "      <td>рф подписывать соглашение ущерб свой безопасно...</td>\n",
       "      <td>разумеется договор сокращение наступательный в...</td>\n",
       "      <td>москва 3 фев риа новость весь решение сфера бе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>https://ria.ru/20110203/329932778.html</td>\n",
       "      <td>17:27 03.02.2011</td>\n",
       "      <td>чиновник должный рассказывать свой работа теле...</td>\n",
       "      <td>считать представитель любой властный структура...</td>\n",
       "      <td>москва 3 фев риа новость премьер министр рф вл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>https://ria.ru/20110203/329922066.html</td>\n",
       "      <td>16:59 03.02.2011</td>\n",
       "      <td>путин заявлять спокойно относиться критика вра...</td>\n",
       "      <td>слушать некоторый вещь знать самый дело жизнь ...</td>\n",
       "      <td>москва 3 фев риа новость премьер министр рф вл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>https://ria.ru/20110203/329921841.html</td>\n",
       "      <td>16:58 03.02.2011</td>\n",
       "      <td>путин говорить дружить свой дочь</td>\n",
       "      <td>премьер признаваться удаваться дружить дочь ра...</td>\n",
       "      <td>москва 3 фев риа новость премьер министр рф вл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>https://ria.ru/20110203/329915820.html</td>\n",
       "      <td>16:45 03.02.2011</td>\n",
       "      <td>силовик шокировать свой отдых нужно увольнять ...</td>\n",
       "      <td>человек который нести служба особый условие ри...</td>\n",
       "      <td>москва 3 фев риа новость правоохранительный ор...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       link              date  \\\n",
       "0    https://ria.ru/20110211/333378123.html  19:57 11.02.2011   \n",
       "1    https://ria.ru/20110211/333385555.html  20:13 11.02.2011   \n",
       "2    https://ria.ru/20110211/333377675.html  19:56 11.02.2011   \n",
       "3    https://ria.ru/20110211/333366199.html  19:26 11.02.2011   \n",
       "4    https://ria.ru/20110211/333358165.html  19:05 11.02.2011   \n",
       "..                                      ...               ...   \n",
       "194  https://ria.ru/20110203/329935025.html  17:32 03.02.2011   \n",
       "195  https://ria.ru/20110203/329932778.html  17:27 03.02.2011   \n",
       "196  https://ria.ru/20110203/329922066.html  16:59 03.02.2011   \n",
       "197  https://ria.ru/20110203/329921841.html  16:58 03.02.2011   \n",
       "198  https://ria.ru/20110203/329915820.html  16:45 03.02.2011   \n",
       "\n",
       "                                                 title  \\\n",
       "0    активист хабаровск приносить консульство япони...   \n",
       "1    токио протестовать против медведев снова поеха...   \n",
       "2                                 иран назло весь враг   \n",
       "3    российский нация должный состоять самобытный н...   \n",
       "4    медведев называть межнациональный единство пер...   \n",
       "..                                                 ...   \n",
       "194  рф подписывать соглашение ущерб свой безопасно...   \n",
       "195  чиновник должный рассказывать свой работа теле...   \n",
       "196  путин заявлять спокойно относиться критика вра...   \n",
       "197                   путин говорить дружить свой дочь   \n",
       "198  силовик шокировать свой отдых нужно увольнять ...   \n",
       "\n",
       "                                              announce  \\\n",
       "0    активист молодежный движение хабаровск приноси...   \n",
       "1    выражать серьезный протест отношение визит сос...   \n",
       "2    иран отмечать 32 годовщина исламский революция...   \n",
       "3    большой задача касаться формирование будущий и...   \n",
       "4    межнациональный единство мочь государство оно ...   \n",
       "..                                                 ...   \n",
       "194  разумеется договор сокращение наступательный в...   \n",
       "195  считать представитель любой властный структура...   \n",
       "196  слушать некоторый вещь знать самый дело жизнь ...   \n",
       "197  премьер признаваться удаваться дружить дочь ра...   \n",
       "198  человек который нести служба особый условие ри...   \n",
       "\n",
       "                                                  text  \n",
       "0                                                  NaN  \n",
       "1    москва 11 фев риа новость япония категорически...  \n",
       "2    иран отмечать 32 годовщина исламский революция...  \n",
       "3    уфа 11 фев риа новость президент рф дмитрий ме...  \n",
       "4    уфа 11 фев риа новость руководитель весь регио...  \n",
       "..                                                 ...  \n",
       "194  москва 3 фев риа новость весь решение сфера бе...  \n",
       "195  москва 3 фев риа новость премьер министр рф вл...  \n",
       "196  москва 3 фев риа новость премьер министр рф вл...  \n",
       "197  москва 3 фев риа новость премьер министр рф вл...  \n",
       "198  москва 3 фев риа новость правоохранительный ор...  \n",
       "\n",
       "[199 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('ria_politics/prep_cites/200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2bd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "with open('/Users/eugenborisenko/Desktop/Универ мага/Диссертация/Парсеры сайтов/ria_economy/raw_preview/news_ria14oct15.html') as file:\n",
    "    src = file.read()\n",
    "\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "items_divs = soup.find_all('div', class_='list-item')\n",
    "\n",
    "for item in items_divs:\n",
    "    item_url = item.find('div', class_='list-item__content').find('a').get('href')\n",
    "    if item_url not in urls:\n",
    "        urls.append(item_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b274c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'link': [], 'data_or_ex': []}\n",
    "total_news = len(urls)\n",
    "current_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df9678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 saved\n",
      "200 saved\n",
      "oil_cost_november_01112015\n",
      "Invalid URL 'oil_cost_november_01112015': No scheme supplied. Perhaps you meant http://oil_cost_november_01112015?\n",
      "currency_november_01112015\n",
      "Invalid URL 'currency_november_01112015': No scheme supplied. Perhaps you meant http://currency_november_01112015?\n",
      "stock_market_november_01112015\n",
      "Invalid URL 'stock_market_november_01112015': No scheme supplied. Perhaps you meant http://stock_market_november_01112015?\n",
      "400 saved\n",
      "600 saved\n",
      "summit_GECF_23112015\n",
      "Invalid URL 'summit_GECF_23112015': No scheme supplied. Perhaps you meant http://summit_GECF_23112015?\n",
      "800 saved\n",
      "1000 saved\n",
      "Manila_APEC_summit_17112015\n",
      "Invalid URL 'Manila_APEC_summit_17112015': No scheme supplied. Perhaps you meant http://Manila_APEC_summit_17112015?\n",
      "1200 saved\n",
      "1400 saved\n",
      "1600 saved\n",
      "1800 saved\n",
      "2000 saved\n",
      "2200 saved\n",
      "2400 saved\n",
      "2600 saved\n",
      "2800 saved\n",
      "3000 saved\n",
      "oil_cost_october_01102015\n",
      "Invalid URL 'oil_cost_october_01102015': No scheme supplied. Perhaps you meant http://oil_cost_october_01102015?\n",
      "currency_October_01102015\n",
      "Invalid URL 'currency_October_01102015': No scheme supplied. Perhaps you meant http://currency_October_01102015?\n",
      "stock_market_october_01102015\n",
      "Invalid URL 'stock_market_october_01102015': No scheme supplied. Perhaps you meant http://stock_market_october_01102015?\n",
      "3200 saved\n",
      "3400 saved\n",
      "3600 saved\n",
      "3800 saved\n",
      "4000 saved\n",
      "4200 saved\n",
      "4400 saved\n"
     ]
    }
   ],
   "source": [
    "start_parsing(urls, n_threads=2, save_evry=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (v3.8.5:580fbb018f, Jul 20 2020, 12:11:27) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
